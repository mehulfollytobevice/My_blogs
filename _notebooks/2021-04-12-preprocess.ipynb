{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-04-12-preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOshlfA66ww0ckN0ziCVgsf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j72e-lT4O-bN"
      },
      "source": [
        "# The essentials of data preprocessing for tabular data \n",
        "> In this blog post  we will explore the essential steps you need to take to preprocess your data and ensure that it is in the right form before you dump it in your \"fancy\"  ML/DL model. \n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: Mehul Jain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLu20AxMPzT_"
      },
      "source": [
        "If you ask data scientists which part of the ML pipeline takes the most amount of time, they will probably tell you that it's the data preprocessing stage. Ensuring your data is in the right form before you dump it into your ML/DL model is of paramount importance. If you feed in garbage to your model, you will get garbage as the output. In this blog post we will see some of the essential techniques that you can use to preprocess your data properly.\n",
        "\n",
        "But first, we need to get some data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utm8wLxjSu4A"
      },
      "source": [
        "## Downloading dataset from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB2dHiAKTJ0a"
      },
      "source": [
        "This notebook is built using Google Colab. It is a notebook server provided by Google for free. You can also use other services to run the code below but you will have to figure out how to get the dataset. The dataset that we use here is present on Kaggle and you can directly download it from [here](https://www.kaggle.com/spscientist/students-performance-in-exams?select=StudentsPerformance.csv).\n",
        "\n",
        "In this notebook, we are going to download the dataset from Kaggle into Google Colab and store it in a directory in our Google Drive. Storing your data in the Drive saves you from the trouble of downloading the dataset every time you start a new session  in Colab. \n",
        "\n",
        "For further guidance read this wonderful article by Mrinali Gupta: [How to fetch Kaggle Datasets into Google Colab](https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a)\n",
        "\n",
        "So let's get to it!\n",
        "\n",
        "First, we need to mount our google drive so that we can access all the folders in the drive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK0tC6b4xqJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd95e560-39f3-41a2-adc5-398e7ef1aaf8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuLyK3OsYFWO"
      },
      "source": [
        "Then we will using the following code to provide a config path for the Kaggle Json API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5iGpIJDlrU1"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/kaggle/StudentPerformance\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ7sXnHLYXD8"
      },
      "source": [
        "We will change our current directory to where we want the dataset to be downloaded "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u52GQxTVlssU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5809ecd8-9e37-4c68-9b87-1fb1620ba5b8"
      },
      "source": [
        "%cd /content/gdrive/My Drive/kaggle/StudentPerformance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/kaggle/StudentPerformance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC7yIEZyExk9"
      },
      "source": [
        "Now we can download the dataset from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0K5mGKTmMYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8eae03a-9eec-48a5-9a6e-751c4eb5599d"
      },
      "source": [
        "!kaggle datasets download -d spscientist/students-performance-in-exams"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading students-performance-in-exams.zip to /content/gdrive/My Drive/kaggle/StudentPerformance\n",
            "\r  0% 0.00/8.70k [00:00<?, ?B/s]\n",
            "\r100% 8.70k/8.70k [00:00<00:00, 1.14MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2ynu4D4E39U"
      },
      "source": [
        "Let's unzip the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjXQlkc6mVyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0a6411-a348-4735-d672-341cdda240e9"
      },
      "source": [
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  students-performance-in-exams.zip\n",
            "  inflating: StudentsPerformance.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsQ46Ic_E7Ue"
      },
      "source": [
        "What files are present in the current directory?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvOgt1d8vA4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144a6872-b9c8-4326-c1fd-e8aace597feb"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  StudentsPerformance.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0wArpAAq2DZ"
      },
      "source": [
        "You can see that there is a \"StudentsPerformance.csv\" file present in the directory. That is our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLh-RrDNWrse"
      },
      "source": [
        "## Exploring the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeAkggBmrluO"
      },
      "source": [
        "Before we apply any preprocessing steps to the data, we need to know what kind of data the dataset contains. Is it textual data? Is it numerical data? Are there any dates present? What about geographic locations?\n",
        "\n",
        "There are a lot of questions we can ask about the data in out dataset. So before we move further, we need to get a sense of what hidden knowledge our dataset contains.\n",
        "\n",
        "In the code cells below you will see some of the most common steps you can apply to gather information about your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLtmdqpj2uk9"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"StudentsPerformance.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMq3lMwZ4EBm"
      },
      "source": [
        "***First 5 rows of the dataset*** <br>Seeing the first and last few rows can be really helpul in creating a mental picture about the data. It also allows you to map out the possible roadblocks you are going to face in acheiving your end goal.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "qhpVlrYW32Rj",
        "outputId": "949b0cfc-9d5a-4b71-c786-bb2683aed113"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>race/ethnicity</th>\n",
              "      <th>parental level of education</th>\n",
              "      <th>lunch</th>\n",
              "      <th>test preparation course</th>\n",
              "      <th>math score</th>\n",
              "      <th>reading score</th>\n",
              "      <th>writing score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>female</td>\n",
              "      <td>group B</td>\n",
              "      <td>bachelor's degree</td>\n",
              "      <td>standard</td>\n",
              "      <td>none</td>\n",
              "      <td>72</td>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>group C</td>\n",
              "      <td>some college</td>\n",
              "      <td>standard</td>\n",
              "      <td>completed</td>\n",
              "      <td>69</td>\n",
              "      <td>90</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>group B</td>\n",
              "      <td>master's degree</td>\n",
              "      <td>standard</td>\n",
              "      <td>none</td>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>group A</td>\n",
              "      <td>associate's degree</td>\n",
              "      <td>free/reduced</td>\n",
              "      <td>none</td>\n",
              "      <td>47</td>\n",
              "      <td>57</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>male</td>\n",
              "      <td>group C</td>\n",
              "      <td>some college</td>\n",
              "      <td>standard</td>\n",
              "      <td>none</td>\n",
              "      <td>76</td>\n",
              "      <td>78</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender race/ethnicity  ... reading score writing score\n",
              "0  female        group B  ...            72            74\n",
              "1  female        group C  ...            90            88\n",
              "2  female        group B  ...            95            93\n",
              "3    male        group A  ...            57            44\n",
              "4    male        group C  ...            78            75\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CnCIhxg4HJ6"
      },
      "source": [
        "***Last 5 rows of the dataset***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "uS9OFzTX4AmM",
        "outputId": "50706889-cde2-43b2-d34a-88831b65fd96"
      },
      "source": [
        "df.tail(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>race/ethnicity</th>\n",
              "      <th>parental level of education</th>\n",
              "      <th>lunch</th>\n",
              "      <th>test preparation course</th>\n",
              "      <th>math score</th>\n",
              "      <th>reading score</th>\n",
              "      <th>writing score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>female</td>\n",
              "      <td>group E</td>\n",
              "      <td>master's degree</td>\n",
              "      <td>standard</td>\n",
              "      <td>completed</td>\n",
              "      <td>88</td>\n",
              "      <td>99</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>male</td>\n",
              "      <td>group C</td>\n",
              "      <td>high school</td>\n",
              "      <td>free/reduced</td>\n",
              "      <td>none</td>\n",
              "      <td>62</td>\n",
              "      <td>55</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>female</td>\n",
              "      <td>group C</td>\n",
              "      <td>high school</td>\n",
              "      <td>free/reduced</td>\n",
              "      <td>completed</td>\n",
              "      <td>59</td>\n",
              "      <td>71</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>female</td>\n",
              "      <td>group D</td>\n",
              "      <td>some college</td>\n",
              "      <td>standard</td>\n",
              "      <td>completed</td>\n",
              "      <td>68</td>\n",
              "      <td>78</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>female</td>\n",
              "      <td>group D</td>\n",
              "      <td>some college</td>\n",
              "      <td>free/reduced</td>\n",
              "      <td>none</td>\n",
              "      <td>77</td>\n",
              "      <td>86</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     gender race/ethnicity  ... reading score writing score\n",
              "995  female        group E  ...            99            95\n",
              "996    male        group C  ...            55            55\n",
              "997  female        group C  ...            71            65\n",
              "998  female        group D  ...            78            77\n",
              "999  female        group D  ...            86            86\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDtmZVPo4K-D"
      },
      "source": [
        "***Information about data type of columns and null values*** <br>\n",
        "Knowing the data type of each column is crucial is choosing the right preprocessing step for that column as well as understanding what the values in the column represent. \n",
        "\n",
        "Another crucial piece of information is the number of non-null values. It helps you in deciding which columns need imputation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtEMcDLK4DYa",
        "outputId": "0b90958b-21ee-42c6-8198-75a232f2d778"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 8 columns):\n",
            " #   Column                       Non-Null Count  Dtype \n",
            "---  ------                       --------------  ----- \n",
            " 0   gender                       1000 non-null   object\n",
            " 1   race/ethnicity               1000 non-null   object\n",
            " 2   parental level of education  1000 non-null   object\n",
            " 3   lunch                        1000 non-null   object\n",
            " 4   test preparation course      1000 non-null   object\n",
            " 5   math score                   1000 non-null   int64 \n",
            " 6   reading score                1000 non-null   int64 \n",
            " 7   writing score                1000 non-null   int64 \n",
            "dtypes: int64(3), object(5)\n",
            "memory usage: 62.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvfT2esV6cM7"
      },
      "source": [
        "***Checking if the dataset has null values*** <br>\n",
        "In the last cell, we saw how you can see if there are null values in your dataset. Below is another method to confirm if your data has any null/ missing values. As you can see below, this dataset does not have any null values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evZxgv7c5fNV",
        "outputId": "bb081289-6c2b-4697-eaef-e4e1133a7c93"
      },
      "source": [
        "for i in list(df.columns):\n",
        "  bool_series=pd.isnull(df[i])\n",
        "  print(\"Column:{} has {} null values.\".format(i,df[bool_series].shape[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column:gender has 0 null values.\n",
            "Column:race/ethnicity has 0 null values.\n",
            "Column:parental level of education has 0 null values.\n",
            "Column:lunch has 0 null values.\n",
            "Column:test preparation course has 0 null values.\n",
            "Column:math score has 0 null values.\n",
            "Column:reading score has 0 null values.\n",
            "Column:writing score has 0 null values.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSy7x6vT42iL"
      },
      "source": [
        "***Describing the numerical columns in the dataset***<br>\n",
        "If you are applying regression or even classification, knowing the summary statistics might help you in deciding how you want to handle the numerical features. Maybe you have to apply some transformations before you apply regression. Maybe the numerical features can be dropped in case they do not contribute much.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "u4jnL60v4PnC",
        "outputId": "ddf8d39b-30da-4fbd-bfe2-8b4b964a0e31"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>math score</th>\n",
              "      <th>reading score</th>\n",
              "      <th>writing score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>66.08900</td>\n",
              "      <td>69.169000</td>\n",
              "      <td>68.054000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>15.16308</td>\n",
              "      <td>14.600192</td>\n",
              "      <td>15.195657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>57.00000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>57.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>66.00000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>69.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>77.00000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>79.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.00000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       math score  reading score  writing score\n",
              "count  1000.00000    1000.000000    1000.000000\n",
              "mean     66.08900      69.169000      68.054000\n",
              "std      15.16308      14.600192      15.195657\n",
              "min       0.00000      17.000000      10.000000\n",
              "25%      57.00000      59.000000      57.750000\n",
              "50%      66.00000      70.000000      69.000000\n",
              "75%      77.00000      79.000000      79.000000\n",
              "max     100.00000     100.000000     100.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxRk8JPI5A8Z"
      },
      "source": [
        "***How many unique values does each column have*** <br>\n",
        "You might want to know how many unique values each column has. This is helpful when you have a big dataset and you are thinking of generating more features from the existing features. This is also important when you are dealing with cases where the [Curse of Dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality) becomes relevant. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClAG4OO54SnL",
        "outputId": "a02a4f06-61af-446b-8798-e8c02f9c77da"
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender                          2\n",
              "race/ethnicity                  5\n",
              "parental level of education     6\n",
              "lunch                           2\n",
              "test preparation course         2\n",
              "math score                     81\n",
              "reading score                  72\n",
              "writing score                  77\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OwpC0Lh2_eD"
      },
      "source": [
        "## The essential preprocessing techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y48gd9T55N0e"
      },
      "source": [
        "In this section, we will cover the essential preprocessing techniques you can apply to your data before feeding it into your model. This is by no means an exhaustive list of techniques you can apply, but this covers the most common techinques applied in the ML industry.\n",
        "\n",
        "The order in which we apply these techniques is very important since each preprocessing step transforms the data such that it may become incompatible for another preprocessing step. \n",
        "\n",
        "We are going to apply our preprocessing techniques in the following order :\n",
        "1. Label Encoding (if needed)\n",
        "2. One-hot Encoding\n",
        "3. Imputation\n",
        "5. Normalization or Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuuV7C0WDk9I"
      },
      "source": [
        "### Label Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHRqv3d3APOu"
      },
      "source": [
        "We saw in the previous section that our data cantains columns which have string values. Although, we can  understand what these string values represent, a machine does not. So , to make these values machine-readable we have to find a way to represent them numerically. Label Encoding is one such method of accomplishing this. \n",
        "\n",
        "In Label Encoding, we assign a unique integer value to each class in the data. This means that the gender column in our dataset will be encoded like so:\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td><b>Original values</b></td>\n",
        "<td>Male</td>\n",
        "<td>Female</td>\n",
        "</tr>\n",
        "<td><b>Label Encoded values</b></td>\n",
        "<td>0</td>\n",
        "<td>1</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Let's see this in action. We are going to label encode the following columns in our dataset:\n",
        "\n",
        "\n",
        "*   gender\t\n",
        "* race/ethnicity\t\n",
        "* parental level of education\t\n",
        "* lunch\t\n",
        "* test preparation course\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "DFlbEZvH5Coq",
        "outputId": "11611fec-eba7-4158-e59e-3e3dff2162b9"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "data=df.copy() # creating a copy of our data since we do not want to change the original dataset\n",
        "for i in list(data.columns)[:5]:\n",
        "  data[i]=LabelEncoder().fit_transform(data[i])\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>race/ethnicity</th>\n",
              "      <th>parental level of education</th>\n",
              "      <th>lunch</th>\n",
              "      <th>test preparation course</th>\n",
              "      <th>math score</th>\n",
              "      <th>reading score</th>\n",
              "      <th>writing score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>69</td>\n",
              "      <td>90</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>57</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>78</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender  race/ethnicity  ...  reading score  writing score\n",
              "0       0               1  ...             72             74\n",
              "1       0               2  ...             90             88\n",
              "2       0               1  ...             95             93\n",
              "3       1               0  ...             57             44\n",
              "4       1               2  ...             78             75\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-VL7Rd4F6kL"
      },
      "source": [
        "Although Label Encoding can be useful in many cases, there is a caveat. An algorithm will not be able to differentiate between a numerical variable and a label encoded variable. Due to this limitation, the values in the label encoded columns might be misunderstood. So  in our gender column, '1' might be given a higher priority than '0' even when no numerical relation exists between the two classes.  \n",
        "\n",
        "Due to this limitation, we need to find a better way of representing our categorical variables in a numerical form. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFbL3Ftt46FX"
      },
      "source": [
        "### One-hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVVsRkfyOzGP"
      },
      "source": [
        "Due to the shortcomings of Label Encoding, we cannot apply it to transform categorical variables into numerical values. Instead, we use One-Hot Encoding. In One-Hot Encoding, we take the n categories in a column and create n or n-1 columns from them. The new columns contain only binary values (0 or 1). So, if our gender column is one-hot encoded, then we will have two new columns: Male and Female. The values in these columns will be 0 (Male column) and 1 (Female column) if a row earlier had 'female' as the gender and vice versa.\n",
        "\n",
        "Let's see how to implement this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "rzN07Viy4-o1",
        "outputId": "fd80201c-603d-4e64-96c4-47f41911ed1e"
      },
      "source": [
        "df=pd.get_dummies(data=df,drop_first=True) #drop_first can also be False\n",
        "df.head(5) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>math score</th>\n",
              "      <th>reading score</th>\n",
              "      <th>writing score</th>\n",
              "      <th>gender_male</th>\n",
              "      <th>race/ethnicity_group B</th>\n",
              "      <th>race/ethnicity_group C</th>\n",
              "      <th>race/ethnicity_group D</th>\n",
              "      <th>race/ethnicity_group E</th>\n",
              "      <th>parental level of education_bachelor's degree</th>\n",
              "      <th>parental level of education_high school</th>\n",
              "      <th>parental level of education_master's degree</th>\n",
              "      <th>parental level of education_some college</th>\n",
              "      <th>parental level of education_some high school</th>\n",
              "      <th>lunch_standard</th>\n",
              "      <th>test preparation course_none</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>72</td>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>90</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47</td>\n",
              "      <td>57</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>76</td>\n",
              "      <td>78</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   math score  reading score  ...  lunch_standard  test preparation course_none\n",
              "0          72             72  ...               1                             1\n",
              "1          69             90  ...               1                             0\n",
              "2          90             95  ...               1                             1\n",
              "3          47             57  ...               0                             1\n",
              "4          76             78  ...               1                             1\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ab8CKl6TQ_r"
      },
      "source": [
        "In the above code, the function has a parameter *drop_first*. What does this mean? In one-hot encoding, we usually drop one of the columns created for each categorical variable to avoid high correlation among the features. But, in many cases dropping columns can have a negative impact on the model performance. So it is always better to experiment and see what works in your case.\n",
        "\n",
        "One-hot encoding is applied in almost all cases where we have to deal with categorical variables. But when the number of categories in a column gets too big, we cannot use this technique since the resulting dataset might be very large and difficult to handle. In this case, you might want to consider other alternatives like dropping the high-cardinality columns, using label encoding, using dimensionality reduction techniques.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkglg4-ImucE"
      },
      "source": [
        "### Imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66GgRJeAmwtb"
      },
      "source": [
        "Dealing with missing data is another important data preprocessing step. Missing values can have huge impacts on how your model performs. If a significant portion of values in a column are missing then you might consider dropping that column. But,dropping columns might actually result in leaving out essential information.So, we apply imputation.\n",
        "\n",
        "In imputation, we replace missing data with substituted values. Here, we will dicuss some of the common ways in which imputation is done:\n",
        "* **Replace by 0:** Sometimes replacing numerical values with 0 can work. Suppose you have an Age column in your dataset. Filling 0 in the places where age is missing might not affect the model's accuracy.\n",
        "* **Replace by mean:** You can also take the mean of all the values in the column and use that to fill the missing places. This is the most common imputation approach. But it is very sensitive to outliers.\n",
        "* **Replace by most_frequent:** You can replace the missing values with the most frequent value. This can work for both categorical and numerical data. \n",
        "* **Replace using custom function:** If you know how a particular column was generated then you can use that process to fill the missing values. Usually, this approach is not applicable since the data is downloaded from elsewhere.\n",
        "\n",
        "In our dataset, we do not have any missing values so we do not need to apply imputation. \n",
        "\n",
        "For futher guidance: [Imputation of missing values](https://scikit-learn.org/stable/modules/impute.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHd53UC95AGi"
      },
      "source": [
        "### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cUAjvIGXm0h"
      },
      "source": [
        "Even after converting our data into a machine readable format, our work is not done. In any dataset, you will have parameters that our measured in different units. For example, you might have Time (measured in hours) and Distance (measured in miles).The values of these parameters will have different distributions and different min/max values. You cannot combine these different parameters using a ML model without taking into account their measurement units.So, we use standardization and normalization.\n",
        "\n",
        "Both of these techniques transform the data in a way such that it either becomes dimensionless (in terms of measurement units)  or the parameters end up having similar distributions. \n",
        "\n",
        "The biggest difference between standardization and normalization is as follows:\n",
        "*  Standardization typically rescales the values to have a mean of 0 and a standard deviation of 1 (unit variance). \n",
        "* Normalization typically rescales the values into a range of [0,1].\n",
        "\n",
        "Because of the difference in the way they transform the values we get a different output in each case.\n",
        "\n",
        "Let's scale our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJWYF3pY5wIq",
        "outputId": "6b277e86-d3e2-4b33-f7e3-4dc9b38c566b"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "data=df.copy()\n",
        "data=StandardScaler().fit_transform(data)\n",
        "data[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.39002351,  0.19399858,  0.39149181, -0.96462528,  2.0647416 ,\n",
              "        -0.68441857, -0.59583014, -0.40347329,  2.73396713, -0.49374193,\n",
              "        -0.2503982 , -0.54036068, -0.4669334 ,  0.74188112,  0.74674788],\n",
              "       [ 0.19207553,  1.42747598,  1.31326868, -0.96462528, -0.4843221 ,\n",
              "         1.46109419, -0.59583014, -0.40347329, -0.36576885, -0.49374193,\n",
              "        -0.2503982 ,  1.85061578, -0.4669334 ,  0.74188112, -1.33914006],\n",
              "       [ 1.57771141,  1.77010859,  1.64247471, -0.96462528,  2.0647416 ,\n",
              "        -0.68441857, -0.59583014, -0.40347329, -0.36576885, -0.49374193,\n",
              "         3.99363901, -0.54036068, -0.4669334 ,  0.74188112,  0.74674788]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWzJdtrnj8wc"
      },
      "source": [
        "Now let's look at normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS0Pqtq75GDO"
      },
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygHBPQLIkFz5"
      },
      "source": [
        "Normalization typically rescales the values into a range of [0,1]. As you will see below, there is a notable difference between the output of standardization and normalization. Normalization will not transform the values of your categorical/one-hot encoded variables in any way. On the other hand, standardization transforms all the columns in the dataset.\n",
        "\n",
        "So, let's normalize our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur-LsvOX50r3",
        "outputId": "d79e8ead-15b0-434e-9683-62c10d468153"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "data=df.copy()\n",
        "data=MinMaxScaler().fit_transform(data)\n",
        "data[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.72      , 0.6626506 , 0.71111111, 0.        , 1.        ,\n",
              "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 1.        , 1.        ],\n",
              "       [0.69      , 0.87951807, 0.86666667, 0.        , 0.        ,\n",
              "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 1.        , 0.        , 1.        , 0.        ],\n",
              "       [0.9       , 0.93975904, 0.92222222, 0.        , 1.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        1.        , 0.        , 0.        , 1.        , 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZSXCu7NksvN"
      },
      "source": [
        "Again, it is very important to experiment with both of these techniques to see which one works for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOIL-h6ftDDm"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E0UpYN5tFKE"
      },
      "source": [
        "In this blog post we have seen the essentials of data preprocessing for tabular data. My goal with this blog post was to provide a condensed overview of the what data preprocessing looks like with useful code snippets that anyone can use in their projects. Applying proper preprocessing can be extremely helpful in improving the model performance and ensuring that your model is ready for the real world. \n",
        "\n",
        "If hope you liked this blog post, please share it with other ML enthusiasts.\n",
        "\n",
        "*See you on the next adventure.*"
      ]
    }
  ]
}